<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					<script type="text/template">
						# Workshop Kafka

						> Arquitecturas dirigidas a eventos usando Kafka

						#### **MÓDULO 4:** Producer/Consumer (delivery semantics)
					</script>
				</section>

				<section>
					<section data-markdown data-background-image="https://media.giphy.com/media/I40IC1hhCpVG5OxaHQ/giphy.gif">
						<script type="text/template">
							
						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							### Productor

							> El productor es una aplicación que envía eventos a un broker. Puede ser 
							la misma aplicación donde ocurre el evento o un itermediario. Por ejemplo, 
							para sistemas monolítcos y legados, se suele usar Kafka Connect.
							
							Más adelante vamos a ve [Debezium](https://debezium.io/) para transformar BD en sistemas orientados a 
							Streaming de Eventos
						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							### Productor

							Es importante garantizar que el productor elija muy bien la llave de cada evento
							para permitir una distribución aceptable. En el caso de eventos pub/sub puros,
							existen mejores soluciones que Kafka ([NATS](https://nats.io/), cof, cof, [NATS](https://nats.io/)).
							Asumiendo el uso para Stream de eventos, recordar que:
							
							- El orden se garantiza por partición, es decir, por llave
							- La unicidad está dada por la llave y es requerida para de-duplicación (salvo que se use Exactly-once)
							- La idempotencia también depende de la llave.

						</script>
					</section>
					<section data-markdown>
						<script type="text/template">
							> La llave tiene que ser de uso genérico. Siempre considerar que es posible mover
							los eventos usando diferentes llaves y tópicos para cubrir diferentes agregaciones o
							agrupaciones y todo esto en tiempo real, esa es una de las gracias de Kafka, **ÚSALO!**

						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							### ¿Cuántos tópicos y cómo elegirlos?

							> En estricto rigor, un tópico permite a un consumidor especificar un sub-conjunto de
							mensajes que quiere consumir.

							* Es cierto que se pueden filtrar los mensajes basados en headers, pero mientras más tipos
							de mensajes en un tópico, más ineficiente es la lectura retro-activa (una de las gracias de Kafka)
							y más mensajes se necesitan escuchar para recibir los que se necesitan.

						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							### ¿Cuántos tópicos y cómo elegirlos?

							> Las particiones son lo que define el desempeño y la utilidad de kafka

							La primera respuesta es tener tantos tópicos para permitir suficientes particiones
							para trabajar con ellas, pero no tantos para que cada partición contenga 
							demasiado pocos eventos.

						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							> Una regla heurística para no afectar la latencia, es tener
							del orden de magnitud de cientos de particiones por broker. En varias
							implementaciones se ha visto que miles comienza a ser un problema. Decenas,
							cae dentro del orden don Kafka no es tan útil.

							* ¿Por qué cientos?, ¿Qué sucede si no tengo datos suficientes? -> 
							Probablemente Kafka sea una solución exagerada :).

						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							¿Por qué se asume que siempre vas a querer más particiones?

							- Más particiones aumentan el Throughput
							
							... pero requiere más archivos abiertos, latencia en selección de líderes 
							(problemas de disponibilidad), aumenta la latencia y requiere más memoria en el cliente.
						</script>
					</section>
					<section data-markdown>
						<script type="text/template">
							### No es una BD relacional, Tópico <> Tabla!

							Para dejar claro, el tópico es una agrupación general, lo que define un evento es su llave.
							
							> Un error común es obligar a que un tópico agrupe eventos del mismo tipo.

							Para eventos que requieren esquemas como logs de actividades, tiene sentido tener tópicos 
							específicos, no así para Micro-Servicios.

						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							> Por ejemplo, para un micro-servicio (dominio) Cliente. Muchas cosas
							pueden suceder a un cliente, como ser creado, cambiar de teléfono o dirección,
							pagar, solicitar soporte, etc. 

							Los eventos de un dominio, pueden ser mucho y no son predecible. Tampoco es predecible 
							conocer que tipos de eventos va a necesitar otro dominio suscrito a Cliente.
						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							### ¿Qué sucede con el orden?

							Recordar que el orden está garantizado por partición y por llave. Para garantizar el orden
							para cierto tipo de evento, se debe diseñar la llave de forma que todos los eventos relacionados
							de un tipo, siempre estén en la misma partición. Luego, sólo es necesario filtrar.

							> En el caso del cliente, el ID de cliente como llave, es suficiente. 
							Todos los eventos relacionados con un cliente particular, va a estar en la misma partición.
						</script>
					</section>
					<section data-markdown>
						<script type="text/template">
							### ¿Qué sucede si uso un tópico por tipo de evento?
							
							Si tengo un evento para creación y cambio de dirección, no se garantiza el orden para
							un cliente particular. Puede ser peor si es para un pago. Agregar un timestamp o un indicador
							de orden, hace que todos los beneficios de usar Kafka no se aprovechen.

						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							### Resumen

							- Todos los eventos que deben seguir un orden según una llave, deben estar
							en el mismo tópico.
							- Si 2 entidades tienen una dependencia, deberían estar en el mismo tópico,
							si no están relacionadas, deberían estar en diferentes.

						</script>
					</section>
				</section>


				<section>
					<section data-markdown>
						<script type="text/template">
							### Productor - ¿Qué debería ir en un evento?

							Luego de la llave es importante la decisión de que va en un evento. Tenemos 2 casos principales:

							- El evento afecta a una sóla entidad.
							- El evento afecta a varias entidades.

						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							### El evento afecta a una sóla entidad

							En este caso, debe ir:

							- Todo lo necesario para identificar inequívocamente la entidad (idealmente la llave).
							- Todo los datos relacionados con el cambio de estado (la diferencia entre el estado anterior 
							y el estado actual).

						</script>
					</section>
				</section>

				<section>
					<section data-markdown>
						<script type="text/template">
							### Pensando en Event Sourcing

							> No es necesario enviar el estado completo en cada evento. El estado se puede reconstruir
							a partir de la historia y también se pueden establecer "checkpoints" de estado consolidado
							cada cierto tiempo o número de mensajes.

						</script>
					</section>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
